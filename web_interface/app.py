import os
from flask import Flask, request, render_template, redirect
import pandas as pd
import joblib
import pefile
import array
import math
import pickle
import PyPDF2
import docx
from bs4 import BeautifulSoup
import numpy as np
import cv2
from joblib import load

app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = 'uploads'

def get_entropy(data):
    if len(data) == 0:
        return 0.0
    occurences = array.array('L', [0]*256)
    for x in data:
        occurences[x if isinstance(x, int) else ord(x)] += 1

    entropy = 0
    for x in occurences:
        if x:
            p_x = float(x) / len(data)
            entropy -= p_x * math.log(p_x, 2)

    return entropy

def extract_pe_info(fpath):
    pe = pefile.PE(fpath)
    res = {
        'Machine': pe.FILE_HEADER.Machine,
        'SizeOfOptionalHeader': pe.FILE_HEADER.SizeOfOptionalHeader,
        'Characteristics': pe.FILE_HEADER.Characteristics,
        'MajorLinkerVersion': pe.OPTIONAL_HEADER.MajorLinkerVersion,
        'MinorLinkerVersion': pe.OPTIONAL_HEADER.MinorLinkerVersion,
        'SizeOfCode': pe.OPTIONAL_HEADER.SizeOfCode,
        'SizeOfInitializedData': pe.OPTIONAL_HEADER.SizeOfInitializedData,
        'SizeOfUninitializedData': pe.OPTIONAL_HEADER.SizeOfUninitializedData,
        'AddressOfEntryPoint': pe.OPTIONAL_HEADER.AddressOfEntryPoint,
        'BaseOfCode': pe.OPTIONAL_HEADER.BaseOfCode,
        'ImageBase': pe.OPTIONAL_HEADER.ImageBase,
        'SectionAlignment': pe.OPTIONAL_HEADER.SectionAlignment,
        'FileAlignment': pe.OPTIONAL_HEADER.FileAlignment,
        'MajorOperatingSystemVersion': pe.OPTIONAL_HEADER.MajorOperatingSystemVersion,
        'MinorOperatingSystemVersion': pe.OPTIONAL_HEADER.MinorOperatingSystemVersion,
        'MajorImageVersion': pe.OPTIONAL_HEADER.MajorImageVersion,
        'MinorImageVersion': pe.OPTIONAL_HEADER.MinorImageVersion,
        'MajorSubsystemVersion': pe.OPTIONAL_HEADER.MajorSubsystemVersion,
        'MinorSubsystemVersion': pe.OPTIONAL_HEADER.MinorSubsystemVersion,
        'SizeOfImage': pe.OPTIONAL_HEADER.SizeOfImage,
        'SizeOfHeaders': pe.OPTIONAL_HEADER.SizeOfHeaders,
        'CheckSum': pe.OPTIONAL_HEADER.CheckSum,
        'Subsystem': pe.OPTIONAL_HEADER.Subsystem,
        'DllCharacteristics': pe.OPTIONAL_HEADER.DllCharacteristics,
        'SizeOfStackReserve': pe.OPTIONAL_HEADER.SizeOfStackReserve,
        'SizeOfStackCommit': pe.OPTIONAL_HEADER.SizeOfStackCommit,
        'SizeOfHeapReserve': pe.OPTIONAL_HEADER.SizeOfHeapReserve,
        'SizeOfHeapCommit': pe.OPTIONAL_HEADER.SizeOfHeapCommit,
        'LoaderFlags': pe.OPTIONAL_HEADER.LoaderFlags,
        'NumberOfRvaAndSizes': pe.OPTIONAL_HEADER.NumberOfRvaAndSizes,
        'SectionsNb': len(pe.sections),
        'SectionsMeanEntropy': sum([x.get_entropy() for x in pe.sections]) / len(pe.sections),
        'SectionsMinEntropy': min([x.get_entropy() for x in pe.sections]),
        'SectionsMaxEntropy': max([x.get_entropy() for x in pe.sections]),
        'SectionsMeanRawsize': sum([x.SizeOfRawData for x in pe.sections]) / len(pe.sections),
        'SectionsMinRawsize': min([x.SizeOfRawData for x in pe.sections]),
        'SectionsMaxRawsize': max([x.SizeOfRawData for x in pe.sections]),
        'SectionsMeanVirtualsize': sum([x.Misc_VirtualSize for x in pe.sections]) / len(pe.sections),
        'SectionsMinVirtualsize': min([x.Misc_VirtualSize for x in pe.sections]),
        'SectionsMaxVirtualsize': max([x.Misc_VirtualSize for x in pe.sections]),
    }
    return res

def extract_pdf_info(fpath):
    with open(fpath, 'rb') as f:
        reader = PyPDF2.PdfReader(f)
        number_of_pages = len(reader.pages)
        text = ''
        for page_num in range(number_of_pages):
            page = reader.pages[page_num]
            text += page.extract_text()
        entropy = get_entropy(text.encode('utf-8'))
    res = {
        'NumberOfPages': number_of_pages,
        'Entropy': entropy,
        'TextLength': len(text)
    }
    return res

def extract_docx_info(fpath):
    doc = docx.Document(fpath)
    text = ''
    for paragraph in doc.paragraphs:
        text += paragraph.text
    entropy = get_entropy(text.encode('utf-8'))
    res = {
        'Paragraphs': len(doc.paragraphs),
        'Entropy': entropy,
        'TextLength': len(text)
    }
    return res

def extract_html_info(fpath):
    with open(fpath, 'r', encoding='utf-8') as f:
        content = f.read()
    soup = BeautifulSoup(content, 'html.parser')
    text = soup.get_text()
    entropy = get_entropy(text.encode('utf-8'))
    tags = len(soup.find_all())
    res = {
        'Tags': tags,
        'Entropy': entropy,
        'TextLength': len(text)
    }
    return res

model_path = r'/home/hp/Desktop/Machine-Learning-main/Machine_Learining _Project/ImageMalware/random_forest_model.pkl'
rf_model = load(model_path)

upload_folder = 'uploads'
app.config['UPLOAD_FOLDER'] = upload_folder

# Function to preprocess the image
def preprocess_image(image_path, size=(64, 64)):
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    resized_image = cv2.resize(image, size)
    flattened_image = resized_image.flatten()
    return flattened_image



def predict_malware(file_path):
    # Load the pre-trained classifier
    classifier = joblib.load('../SignatureMalware/classifier.pkl')
    features = pickle.loads(open(os.path.join('../SignatureMalware/features.pkl'), 'rb').read())

    if file_path.endswith('.exe'):
        file_features = extract_pe_info(file_path)
    elif file_path.endswith('.pdf'):
        file_features = extract_pdf_info(file_path)
    elif file_path.endswith('.docx'):
        file_features = extract_docx_info(file_path)
    elif file_path.endswith('.html') or file_path.endswith('.htm'):
        file_features = extract_html_info(file_path)
    else:
        return "Unsupported file type"

    file_features = list(map(lambda x: file_features.get(x, 0), features))
    prediction = classifier.predict([file_features])[0]
    return prediction


@app.route('/')
def index():
    return render_template('index.html')

@app.route('/file', methods=['GET', 'POST'])
def upload_file():
    if request.method == 'POST':
        if 'file' not in request.files:
            return redirect(request.url)
        file = request.files['file']
        if file.filename == '':
            return redirect(request.url)
        if file:
            file_path = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)
            file.save(file_path)
            prediction = predict_malware(file_path)
            print(prediction)
            result_message = 'est un malware' if prediction == 1 else "n'est pas un malware"
            return render_template('result.html', result_message=result_message)
    return render_template('upload_file.html')

# Route for image upload
@app.route('/image', methods=['GET', 'POST'])
def upload_image():
    if request.method == 'POST':
        if 'file' not in request.files:
            return render_template('upload_image.html', message='No files selected')
        file = request.files['file']
        if file.filename == '':
            return render_template('upload_image.html', message='No files selected')
        if file:
            file_path = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)
            file.save(file_path)
            image = preprocess_image(file_path)
            # Make a prediction with the RandomForestClassifier model
            prediction = rf_model.predict([image])
            return render_template('upload_image.html', message='The type of malware detected is : {}'.format(prediction[0]))
    return render_template('upload_image.html')

if __name__ == '__main__':
    os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
    app.run(debug=True)
